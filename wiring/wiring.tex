\documentclass[10pt, a4paper]{article}

% Page
\usepackage{pdflscape} % make certain pages landscape
\usepackage{geometry} % set page geometry
\usepackage[indent=2em, skip=0.8em plus 0.1 em minus 0.2 em]{parskip} % set paragraph spacing

% Font and Text
\usepackage[utf8]{inputenc}
\usepackage{bbm} % blackboard bold fonts
\usepackage{lmodern} % bold teletype font
\usepackage{csquotes} % allows quoting blocks of text
\usepackage{textcomp} % allow text settings
\usepackage{xcolor} % allows for colouring of source code blocks
\usepackage{url} % better URLs
\usepackage{indentfirst} % indent the first line after a heading
\usepackage{enumitem} % gives alphabet list headers

% Notation
\usepackage{amssymb} % allows for maths mode symbols
\usepackage{amsmath} % allows for many maths mode commands
\usepackage{amsthm} % allows for QED tombstone
\usepackage{mathtools}
\allowdisplaybreaks% allow display elements to break across pages
\usepackage{siunitx} % allows SI units to be formatted
\usepackage{braket} % support Dirac notation
\usepackage{esvect} % nicer vector arrows
\usepackage[thinc]{esdiff} % derivatives 
\usepackage{esint} % integrals
\usepackage{cancel} % allow cancellation

% Tables
\usepackage{tabulary} % allows for better tables
\usepackage{longtable} % allows tables to span pages
\usepackage{makecell} % allow nice table titles
\usepackage[export]{adjustbox} % allow tables to take up the space they need, and export additional scaling stuff for graphicx
\usepackage{diagbox} % diagonal box in table
\usepackage{multirow} % cells in tables can span rows/columns
\usepackage{tablefootnote} % use \tablefootnote for footnotes in tables

% Code
\usepackage{listings} % allows for source code blocks
\usepackage{algorithm} % typeset algorithms
\usepackage{algpseudocode} % pseudocode style algorithms

% Graphics
\usepackage[justification=centering]{caption} % centres captions
\usepackage{float} % stop LaTeX from making stuff float everywhere with H
\usepackage{graphicx} % allows figures to be inserted and scaled
\usepackage{tikz} % programmatically draw stuff
\usepackage{tikzscale} % include .tikz files with includegraphics and scale them
\usetikzlibrary{shapes, shapes.geometric, automata, positioning, arrows}

\RequirePackage{luatex85}
% Default preamble
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usepgfplotslibrary{groupplots}
\usepgfplotslibrary{polar}
\usepgfplotslibrary{smithchart}
\usepgfplotslibrary{statistics}
\usepgfplotslibrary{dateplot}
\usepgfplotslibrary{ternary}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{backgrounds}
\usepgfplotslibrary{patchplots}
\usepgfplotslibrary{fillbetween}
\pgfplotsset{%
  layers/standard/.define layer set={%
    background,axis background,axis grid,axis ticks,axis lines,axis tick labels,pre main,main,axis descriptions,axis foreground%
    }{grid style= {/pgfplots/on layer=axis grid},%
    tick style= {/pgfplots/on layer=axis ticks},%
    axis line style= {/pgfplots/on layer=axis lines},%
    label style= {/pgfplots/on layer=axis descriptions},%
    legend style= {/pgfplots/on layer=axis descriptions},%
    title style= {/pgfplots/on layer=axis descriptions},%
    colorbar style= {/pgfplots/on layer=axis descriptions},%
    ticklabel style= {/pgfplots/on layer=axis tick labels},%
    axis background@ style={/pgfplots/on layer=axis background},%
    3d box foreground style={/pgfplots/on layer=axis foreground},%
  },
}

\tikzset{%
  ->, % makes the edges directed
  >=stealth, % makes the arrow heads bold
  node distance=3cm, % specifies the minimum distance between two nodes. Change if necessary.
  every state/.style={thick, fill=gray!10}, % sets the properties for each ’state’ node
  initial text=$ $, % sets the text that appears on the start arrow
}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codered}{rgb}{0.6,0,0}
\definecolor{codeblue}{rgb}{0,0,0.6}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.95}

\lstset{%
  numbers=left,                   % where to put the line-numbers
  stepnumber=1,                   % the step between two line-numbers.        
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  % breakatwhitespace=true,         % sets if automatic breaks should only happen at whitespace
  upquote=true, 			% set all single quotes to straight quotes
  basicstyle={\ttfamily\small},           % hackerman teletype font
  keywordstyle={\color{codegreen}\bfseries\ttfamily}, % hackerman teletype font
  commentstyle={\color{codeblue}\textit},           % fancy italic comments
  stringstyle={\color{codered}},           % string literal highlighting
  identifierstyle={}, 
  %title=\lstname,                % show the filename of files included with \lstinputlisting;
  frame=single,			% put a frame around the source code
  aboveskip=2em, % add space before code
  inputpath={./code/}
}

% analysis and calculus
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\indif}{{\mathop{}\!\mkern3mu\mathchar'26\mkern-12mu \mathrm{d}}}
\newcommand{\Dif}{\mathop{}\!\mathrm{D}} % Difference operator
\newcommand{\dif}{\mathop{}\!\mathrm{d}} % differential d

% CS, discrete maths, algebra
\DeclareMathSymbol{\lneg}{\mathord}{symbols}{"18} % tildes for negation
\newcommand{\st}{\mathrel{:}} % 'such that'
\newcommand{\?}{\mathrel{?}} % ternary operator
\newcommand{\concat}{\mathbin{\Vert}} % string concatenation operator
\newcommand{\Mod}{~\mathbf{mod}~} % for mod operator
\newcommand{\Div}{~\mathbf{div}~} % for div operator
\newcommand{\Rem}{~\mathbf{rem}~} % for rem operator
\newcommand{\Z}{\mathbb{Z}} % for integers
\newcommand{\R}{\mathbb{R}} % for reals
\newcommand{\C}{\mathbb{C}} % for complex
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil} % enables \ceil{} for ceil delimiter
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor} % enables \floor{} for floor delimiter

% linear algebra
\newcommand{\cvec}[1]{\boldsymbol{\mathbf{#1}}}    % column vectors
\newcommand{\rvec}[1]{\boldsymbol{\mathbf{#1}}^{\mathrm{T}}} % row vectors (transposed from column vectors)
\newcommand{\bvec}[1]{\hat{\boldsymbol{\mathbf{#1}}}} % basis vectors
\newcommand{\matr}[1]{\left[\mathbf{#1}\right]} % matrices
\newcommand{\matrp}[2]{\left[\mathbf{#1}#2\right]} % matrices with subscripts/superscripts
\newcommand{\inner}[2]{\left\langle#1,#2\right\rangle} % inner product
% \newcommand{\dim}{\rm dim} % dimension

% probability and statistics
\newcommand{\rv}[1]{\boldsymbol{\mathbf{#1}}} % random variable
\newcommand{\E}{\mathbb{E}} % expectation
\newcommand{\angleb}[1]{\left\langle #1 \right\rangle} % physicist's notation for mean
\newcommand{\Var}{\mathrm{Var}} % variance
\newcommand{\indep}{\perp \!\!\! \perp} % independence symbol
\newcommand{\indic}[1]{\mathbbm{1}{\left\{#1\right\}}} % indicator function
\newcommand{\iid}{i.i.d.\ } % independently and identically distributed

% quantum physics
\newcommand{\tr}{\mathrm{tr}} % enables Trace operator
\newcommand{\Hs}{\mathcal{H}} % enables H for Hilbert space

% category theory
% \newcommand{\hom}{\mathrm{hom}} % collection of morphisms in a category
\newcommand{\Hom}{\mathrm{Hom}} % collection of between two objects
\newcommand{\ob}{\mathrm{ob}} % collection of objects
\newcommand{\id}{\mathrm{id}} % identity morphism

% Custom lengths
\addtolength{\jot}{0.5em} % gives spacing between align* rows

\newenvironment{Tabular}[1] % less cramped tables
{\def\arraystretch{1.75}\begin{tabular}{#1}}
{\end{tabular}}
\newenvironment{Array*}[1] % less cramped display mode arrays
{\def\arraystretch{1.75}\everymath={\displaystyle}\[\begin{array}{#1}}
{\end{array}\]}
\newenvironment{Array}[1] % less cramped display mode arrays
{\def\arraystretch{1.75}\everymath={\displaystyle}\begin{equation}\begin{array}{#1}}
{\end{array}\end{equation}}
\newenvironment{displaytable}[1] % environment for a simple inline table to present some information
{\vspace\abovedisplayskip\begin{center}\begin{tabular}{#1}}
{\end{tabular}\end{center}\vspace\belowdisplayskip}

\newcommand{\tableline}[1]{\dimexpr \linewidth/#1 - 2\tabcolsep}

% temporarily change margins
\newenvironment{changemargin}[2]{% 
  \begin{list}{}{%
      \setlength{\topsep}{0pt}%
      \setlength{\leftmargin}{#1}%
      \setlength{\rightmargin}{#2}%
      \setlength{\listparindent}{\parindent}%
      \setlength{\itemindent}{\parindent}%
      \setlength{\parsep}{\parskip}%
    }%
\item[]}{\end{list}}

  \usepackage[backend=biber, style=ieee]{biblatex}
  \addbibresource{../wiring.bib}
  % \graphicspath{{../images/}}
  \usepackage{hyperref} % hyperlinks
  \usepackage{bookmark} % PDF bookmarks
  \hypersetup{%
    colorlinks=true,
    linkcolor=purple,
    urlcolor=blue
  }
  \usepackage{cleveref} % references are automatically of the form "Section 1" etc.
  \Crefname{subsection}{Subsection}{Subsections}

  \numberwithin{equation}{section} % eqn counter rolls over at each section

  \newcounter{stmt} % definitions, theorems and lemmas share this counter
  \theoremstyle{definition}
  \newtheorem{defn}[stmt]{Definition}
  \theoremstyle{plain}
  \newtheorem{theorem}[stmt]{Theorem}
  \theoremstyle{plain}
  \newtheorem{lemma}[stmt]{Lemma}

  \newcommand{\sM}{\mathcal{M}}
  \newcommand{\sS}{\mathcal{S}}
  \newcommand{\sK}{\mathcal{K}}
  \newcommand{\sT}{\mathcal{T}}
  \newcommand{\sH}{\mathcal{H}}
  \newcommand{\sV}{\mathcal{V}}
  \newcommand{\sX}{\mathcal{X}}
  \newcommand{\sZ}{\mathcal{Z}}
  \newcommand{\cF}{\mathcal{F}}

  \newcommand{\AU}{\mathrm{AU}_{2}}
  \newcommand{\AXU}{\mathrm{AXU}_{2}}
  \newcommand{\ASU}{\mathrm{ASU}_{2}}
  \newcommand{\eAU}{\epsilon\text{-}\AU}
  \newcommand{\eAXU}{\epsilon\text{-}\AXU}
  \newcommand{\eASU}{\epsilon\text{-}\ASU}

  \newcommand{\frI}{\mathfrak{I}}
  \newcommand{\frX}{\mathfrak{X}}
  \newcommand{\frA}{\mathfrak{A}}
  \newcommand{\frC}{\mathfrak{C}}
  \newcommand{\frR}{\mathfrak{R}}

  \newcommand{\cE}{\mathcal{E}}

  \newcommand{\meas}{\rm meas}
  \newcommand{\perm}{\rm perm}
  \newcommand{\pe}{\rm pe}
  \newcommand{\pa}{\rm pa}
  \newcommand{\ir}{\rm ir}
  \newcommand{\leakir}{\mathrm{leak}_{\ir}}
  \newcommand{\auth}{\rm auth}
  \newcommand{\key}{\rm key}
  \newcommand{\rob}{\rm rob}
  \newcommand{\cor}{\rm cor}
  \newcommand{\secur}{\rm sec}

  \newcommand{\HC}{\mathrm{HC}}
  \newcommand{\MC}{\mathrm{MC}}

  \newcommand{\Ls}{\mathcal{L}}
  \newcommand{\Qs}{\mathcal{Q}}
  \newcommand{\NSs}{\mathcal{NS}}

  \title{Device-independent quantum key distribution with local wiring}
  \author{John Khoo\\ \href{mailto:john_khoo@u.nus.edu}{\texttt{john\_khoo@u.nus.edu}} \\\\ AD MAIOREM DEI GLORIAM} 

  \begin{document}

  \maketitle

  \section{Introduction}

  Device-independent quantum key distribution (DIQKD) is a remarkable form of quantum key distribution (QKD) that relies on fundamental properties of causality in order to certify the security of a generated secret key, removing the need to characterise the physical devices involved in generating them. These devices are then seen as black boxes with classical inputs and outputs, whose statistical correlations can certify the non-classical nature of their internal processes, and therefore the privacy of the generated data. This certification is done using \emph{Bell tests}, which detects the non-classical phenomenon of \emph{nonlocality}. Formally, in each round, the two players Alice and Bob can provide inputs \(x\) and \(y\), respectively, to their devices, and obtain outputs \(a\) and \(b\), respectively. The joint conditional distribution that is observed over asymptotically many rounds is called the \emph{behaviour} \(p(ab|xy)\). The behaviour alone (with a few weak assumptions) is sufficient for Alice and Bob to generate secret keys.

  Despite this extraordinary guarantee of security, progress in understanding and implementing DIQKD has been slow. For example, given a particular behaviour, we do not have a tight expression for the amount of secrecy that can be extracted per use of the devices. This project aims to explore this aspect of DIQKD from two directions. Firstly, we aim to find an upper bound for the DIQKD key rate from a given behaviour, where each round undergoes independent classical post-processing. Secondly, we wish to see if classical post-processing that \emph{combines} multiple rounds to produce a new behaviour can lead to improvements over these upper bounds. This post-processing is referred to as \emph{wiring}, and can be seen as the act of connecting the inputs and outputs of multiple devices together, with arbitrary logic gates between them.

  \subsection{Objectives}

  Our ideal outcome from this project is to find an efficient algorithm that, given a behaviour, can specify the wiring that produces the behaviour with the largest possible keyrate. A trivial, inefficient algorithm would be to simply compute all possible wirings by brute force, although this will necessarily restrict our search to a limited subset of the possible wirings, since we can wire together arbitrarily many boxes. If no such algorithm exists, we would want to understand why. Is it that wiring multiple boxes together cannot give an advantage over post-processing a single box? Is the structure of achievable boxes simply too complex to navigate efficiently?

  While this task is daunting, we hope that, even if we fall far short of this ideal outcome, this project can contribute to a better understanding of the mysterious phenomenon of nonlocality, and to the work of harnessing it for human benefit.

  \subsection{Structure}

  As this is still an interim report, we do not have many concrete results, although we have investigated and tried to understand a variety of techniques for approaching this problem. We first review the basic, relevant notions of nonlocality, then proceed to review some preliminary results. Next, we discuss how we can perform an exhaustive search through the space of possible wirings, followed by a review of techniques for upper bounding and lower bounding the achievable keyrates. Finally, we explore more unconventional approaches to analysing achievable DIQKD rates, namely nonlocality monotones and the structure of the space of achievable correlations.

  \section{Nonlocality Review}

  In this section, we briefly summarise the relevant notions of the theory of nonlocality. A fuller exposition can be found in~\cite{BellNonlocality}. In order to be compatible with the theory of relativity, the behaviour of a device must fulfil the \emph{no-signalling conditions}, which state that the marginal probabilities for each player's output cannot depend on the other player's input:
  \begin{gather}
    \sum_b p(ab|xy) = p(a|xy) = p(a|x)\;\forall a,x,y \\
    \sum_a p(ab|xy) = p(b|xy) = p(b|y)\;\forall b,x,y.
  \end{gather}

  A device must have a concrete number of possible inputs and outputs. We refer to the choice of the number of inputs and outputs as the \emph{setting} \((i_A, o_A, i_B, o_B)\)\footnote{To be more general, we could let each input have its own number of outputs. In Alice's case (Bob's case being analogous), we would have a function \(o_A'(x)\) to determine the number of outputs from \(x\). However, these behaviours would be a subset of the behaviour with a constant \(o_A = \max_x o_A'(x)\), which can reproduce those behaviours by setting \(p(ab|xy) = 0\) for \(a > o_A'(x)\). There is hence no loss of generality in setting \(o_A\) to be a constant.}, where
  \[ x \in \{1, \ldots, i_A\} \qquad a \in \{1, \ldots, o_A\} \qquad y \in \{1, \ldots, i_B\} \qquad b \in \{1, \ldots, o_B\}. \]
  Naively, it would seem that we need \(o_A o_B i_A i_B\) values of the distribution \(p(ab|xy)\), one for each tuple \((a, b, x, y)\), to describe a no-signalling behaviour (that is, a behaviour that fulfills the no-signalling conditions). However, the \emph{Collins-Gisin representation} takes advantage of the no-signalling conditions to reduce this. For each \(x\), \(p(a|x)\) must be normalised, and so the value of \(p(o_A|x)\) for each \(x\) is no longer independent. The same applies to \(p(b|y)\), yielding \((o_A-1)i_A + (o_B-1)i_B\) marginals in total. Similarly, \(p(o_A o_B|xy)\) is fixed by normalisation for a given \((x,y)\).

  Further, the no-signalling condition allows us to recover \emph{any} probability that involves either \(o_A\) or \(o_B\) as
  \begin{gather*}
    p(o_A b|xy) = p(b|y) - \sum_{a < o_A} p(ab|xy)\;\forall b,x,y \\
    p(ao_B|xy) = p(a|x) - \sum_{b < o_B} p(ab|xy)\;\forall a,x,y.
  \end{gather*}
  Therefore, none of the probabilities \(p(ab|xy)\) where \(a = o_A\) or \(b = o_B\) are independent, and we have only \((o_A-1)(o_B-1){i_A}{i_B}\) independent probabilities of this form. Therefore, the number of independent parameters of a no-signalling behaviour is
  \[ D_{NS}(i_A, o_A, i_B, o_B) = (o_A-1)(o_B-1){i_A}{i_B} + (o_A-1)i_A + (o_B-1)i_B, \]
  and behaviours can be seen as vectors in \(\R^{D_{NS}}\), with all entries positive and normalised.

  The space of no-signalling behaviours is the \emph{no-signalling polytope} \(\NSs \in \R^{D_{NS}}\). \(\NSs\) contains the \emph{local polytope} \(\Ls\), which consists of the behaviours that could be produced from pre-shared (and therefore insecure) data. The behaviours we are interested in are those in the \emph{quantum set} \(\Qs\), where \(\Ls \subsetneq \Qs \subsetneq \NSs\), which is the set of behaviours achievable according to quantum theory. This is important because, until quantum theory is superseded, the devices we engineer can only achieve behaviours within \(\Qs\). We will also need quantum theory to characterise the possible attacks against our DIQKD system, and therefore to define our key rates.

  We focus primarily on \emph{binary-output} settings, that is, settings where \(o_A = o_B = 2\), which are simpler to analyse and more helpful for applications. In this case, we can express many statistics of interest in language reminiscent of quantum theory. We define the \emph{observables} \(A_x\) and \(B_y\) for each value of \(x\) and \(y\), respectively, acting on Alice and Bob's respective Hilbert spaces\footnote{More formally, then, the observables are \(A_x \otimes I_B\) and \(I_A \otimes B_y\)}. These Hermitian operators have eigenvalues \(-1\) and \(+1\), corresponding to the measurement outcomes \(0\) and \(1\) respectively.\footnote{Another convention has \(0 \mapsto 1\) and \(1 \mapsto 2\), which is typically followed in code in languages with 1-based array indexing, such as MATLAB and Julia. We will clarify which convention we are using and try to avoid switching between conventions unnecessarily, but we will hold \(\{0,1\}\) as the ``actual'' measurement outcomes.} Each round can then be considered a measurement of the observables corresponding to the chosen measurement setting on an unknown quantum state prepared by the DIQKD system.

  The \emph{expectation values} of the individual observables on the state are the \emph{marginals} \(\angleb{A_x}\) and \(\angleb{B_y}\). We are also interested in the \emph{correlators} \(\angleb{A_x B_y}\). These can be computed as
  \begin{align}
    \angleb{A_x B_y} &= \begin{aligned}[c]
      (1 \times 1 \times p(a=1,b=1|xy)) + (-1 \times -1 \times p(a=0,b=0|xy)) \\
      + (1 \times -1 \times p(a=1,b=0|xy)) + (-1 \times 1 \times p(a=0,b=1|xy))
    \end{aligned} \notag \\
                     &= p(a=b|xy) - p(a\neq b|xy) \\
      \angleb{A_x} &= p(a=1|x) - p(a=0|x) \\
      \angleb{B_y} &= p(b=1|y) - p(b=0|y).
  \end{align}

  In \((2,2,2,2)\), the simplest nontrivial setting, some important statistics are the quantum bit error rate (QBER) \(Q_{xy}\) and the Clauser-Horne-Shimony-Holt (CHSH) value \(S\):
  \begin{gather}
    Q_{xy} \coloneqq p(a \neq b|xy) = \frac{1-\angleb{A_x B_y}}{2} \\
    S \coloneqq \angleb{A_0 B_0} + \angleb{A_1 B_0} + \angleb{A_0 B_1} - \angleb{A_1 B_1}.
  \end{gather}
  Behaviours with \(S > 2\) are not contained in \(\Ls\), while behaviours in \(\Qs\) are constrained to have \(S \leq 2\sqrt{2}\).

  Perhaps the best-known DIQKD protocol is given in~\cite{DIQKD_Lower}, which also gives a formula to explicitly calculate the keyrate \(r\) in terms of \(Q\) and \(S\). This takes place in the \((2,2,3,2)\) setting which we refer to as the \emph{QKD setting}, and uses Alice's and Bob's received outputs in the rounds with \(x = 0, y = 2\) as the key. Therefore, we have \(Q = Q_{02}\) and
  \begin{equation}
    r \geq 1 - h_2(Q) - h_2\left( \frac{1 + \sqrt{{(S/2)}^2-1}}{2} \right),
  \end{equation}
  where \(h_2(x) = - x \log x - (1-x) \log (1-x)\) is the binary entropy function, with the logarithm in base 2. \(S\) here is calculated from \(x,y \in \{0,1\}\). Being the rate for an explicit, achievable protocol, this rate is a lower bound for the total secrecy extractable.

  The derivative of \(h_2(x)\) is
  \[ \diffp{{h_2(x)}}{x} = \frac{1}{\ln 2} \ln \left(\frac{1-x}{x}\right), \]
  from which it can be seen that for \(Q \in [0, 0.5]\), the keyrate increases for decreasing \(Q\). It is always possible to achieve this value of \(Q\) by flipping all bits if the raw value for \(Q\) is \(> 0.5\).

  Simple differentiation also shows that \(r\) increases with increasing \(S\):
  \begin{align*}
    \ln (2) \diffp{r}{S} &= - \left( \diffp{}{S} \frac{1 + \sqrt{(S/2)^2-1}}{2} \right) \ln \left( \frac{1 - \sqrt{(S/2)^2-1}}{2} / \frac{1 + \sqrt{(S/2)^2-1}}{2} \right) \\
                 &= - \left( \frac{1}{4} \left( (S/2)^2-1 \right)^{-1/2} \diffp{}{S} \left[ (S/2)^2-1 \right] \right) \ln \left( \frac{1 - \sqrt{(S/2)^2-1}}{1 + \sqrt{(S/2)^2-1}} \right) \\
                 &= \underbrace{\left( \frac{S}{ 8\sqrt{(S/2)^2-1} } \right)}_{\geq 0} \ln \underbrace{ \left( \frac{1 + \sqrt{(S/2)^2-1}}{1 - \sqrt{(S/2)^2-1}} \right) }_{\geq 1} \because \sqrt{{(S/2)}^2-1} \geq 0 \\
                 &\geq 0.
  \end{align*}

  \section{Preliminary Results}
  
    Consider the following simple wiring, where we broadcast the same inputs \(x\) and \(y\) to \(N\) boxes on each side, and drive an AND gate with all the outputs.

    For \(N\) boxes,
    \begin{gather}
      \angleb{A_x B_y}_{N} = 1 - \frac{{(1-\angleb{B_y})}^N + {(1-\angleb{A_x})}^N}{2^{N-1}} + \frac{1}{4^{N-1}} {(1-\angleb{A_x} - \angleb{B_y} + \angleb{A_x B_y})}^{N} \\
      \angleb{A_x}_{N} = 1 - 2 {\left(\frac{1-\angleb{A_x}}{2}\right)}^N \qquad \angleb{B_y}_{N} = 1 - 2 {\left(\frac{1-\angleb{B_y}}{2}\right)}^N.
    \end{gather}

    Our preliminary results found a revival of the Pironio key rate for states that are generated according to a simple experimental model. In this model, we denote the behaviour given by the states and measurements, assuming a perfect experimental setup, by \(\tilde{p}\), while the observed probability distribution is denoted by \(p\). The probability of no signal being produced is \(n_c\), and the efficiencies of Alice and Bob's detectors are \(\eta_A\) and \(\eta_B\) respectively. When nothing is detected, either due to no signal being produced or due to detector inefficiency, we assign the \(-1\) outcome. Therefore, the observed probabilities are
    \begin{align*}
      p(a|x) &= \delta_{a,-1}(n_c + 1 - \eta_A) + (\eta_A - n_c)\tilde{p}(a|x) \\
      p(b|y) &= \delta_{b,-1}(n_c + 1 - \eta_B) + (\eta_B - n_c)\tilde{p}(b|y) \\
      p(ab|xy) &= \begin{aligned}[c] \delta_{a,-1}\delta_{b,-1}n_c + (1-n_c) [ \delta_{a,-1} \delta_{b,-1}(1-\eta_A\eta_B) + \eta_A\eta_B \tilde{p}(ab|xy) \\
        + \delta_{b,-1}\eta_A(1-\eta_B)\tilde{p}(a|x) + \delta_{a,-1}\eta_B(1-\eta_A)\tilde{p}(b|y) ] 
      \end{aligned}
    \end{align*}

    For our purposes, we fix \(\eta_A = \eta_B = \eta\). Then, we have
    \begin{align*}
      \diffp{}{{n_c}} \angleb{A_x B_y} &= \eta \left( \left(1-\eta\right) \left(\langle\tilde{A}_x\rangle + \langle\tilde{B}_y\rangle\right) - \eta \langle\tilde{A}_x\tilde{B}_y\rangle + \left(2 - \eta\right) \right) \\
      \diffp{}{{\eta}} \angleb{A_x B_y} &= \left(1 - n_{c}\right) \left( \left(1-2\eta\right) \left(\langle\tilde{A}_x\rangle+\langle\tilde{B}_y\rangle\right) - 2\eta \langle\tilde{A}_x\tilde{B}_y\rangle + (2-2\eta) \right) \\
      \diffp{}{S} H^S(A|E) &= \frac{S}{4\sqrt{S^2-4}} \log_2 \left[ \frac{\sqrt{S^2-4}-2}{\sqrt{S^2-4}+2} \right]
    \end{align*}

    \section{Local Wirings}

    \subsection{Classifying Wirings}

    The possible wirings between boxes are sometimes claimed to be classified by the scheme of Short et al.~\cite{ShortEntangleSwap}, for example in~\cite{ShortClassClaim}. This work attempts to generalise joint measurements to the no-signalling setting and finds a polytope of possible operations which happens to have local wirings at its extremal points. For the  \((2,2,2,2)\) setting, there are 82 extremal points, grouped into 5 possible types of wirings: deterministic output, where the input is precisely the output; one-sided, where only one box is used; sequential, where the output of the first box is used as input for the second box, and AND and XOR gated, where the respective gates are used to combine the output of the two boxes.

    However, this does not mean that this polytope exhausts the possible space of local wirings. This section will be devoted to presenting an alternative framework for enumerating the possible wirings, in order to enable an exhaustive search.

    Let each player have \(c\) boxes, and let subscripts denote the order in which the boxes are used. Then, Alice's wiring can be represented by a sequence of \(c\) functions with range \(\{1..i_A\}\)
    \begin{equation} x_1 = x \end{equation}
    \begin{equation} x_j = C_j^A(x_1, \ldots, x_{j-1}, a_1, \ldots, a_{j-1}),\,j \in \{2..c\} \end{equation}
    and a final output function with range \(\{1..o_A\}\)
    \begin{equation} a = C^A(x_1, \ldots, x_{c}, a_1, \ldots, a_{c}). \end{equation}
    Alice and Bob interact with their boxes in increasing order of the index \(j\). The condition that the input to box \(j\) can only depend on the inputs and outputs of boxes with index \(< j\) is equivalent to enforcing that Alice and Bob do not have quantum memories: both players must provide an input to a given box before it can produce an output.
    \begin{table}
      \begin{minipage}{0.5\linewidth}
        \begin{center}
          \begin{tabular}{|r|cc|} \hline
            \diagbox{\(x_1\)}{\(a_1\)} & 0 & 1 \\ \hline
            0 & 1 & 0 \\
            1 & 1 & 1 \\ \hline
          \end{tabular}
        \end{center}
      \end{minipage}
      \begin{minipage}{0.5\linewidth}
        \begin{center}
          \begin{tabular}{|r|cccc|} \hline
            \diagbox{\(x_1 x_2\)}{\(a_1 a_2\)} & 00 & 01 & 11 & 10 \\ \hline
            00 & X & X & 1 & 0 \\
            01 & 0 & 0 & X & X \\
            11 & 1 & 0 & 0 & 0 \\
            10 & X & X & X & X \\ \hline
          \end{tabular}
        \end{center}
      \end{minipage}
      \caption{Left: Lookup table for \(C^A_2\), giving \(x_2\). Right: Lookup table for \(C^A\), giving overall output \(a\). Entries forbidden by \(C^A_2\) are marked with X (don't care). Both are written as Karnaugh maps.}\label{tab:wiring_lut}
    \end{table}

    A wiring corresponding to the lookup tables in~\Cref{tab:wiring_lut} would have
    \begin{equation}
      x_2 = \bar{a}_1x_1 \qquad a = x_1x_2\bar{a}_1\bar{a}_2 + \bar{x}_1\bar{x}_2a_1a_2,
    \end{equation}
    where juxtaposition is the Boolean AND, addition is the Boolean OR, and the overbar is the Boolean NOT.\ This cannot be expressed as one of the wirings from~\cite{ShortEntangleSwap}: the boxes are clearly non-constant and dependent on each other, so they are not one-sided or deterministic, and the functional dependence of the output is too complex to be expressed simply with a single AND or XOR gate.

    The classification of Short et al.\ attempts to find a parametrisation of \emph{couplers}, which are a specific type of transformation which ``collapses'' multiple boxes of one party, replacing their inputs and outputs with a single output, whose probability distribution depends on the behaviours of the individual boxes that are collapsed. Importantly, this \emph{does not} replace the collapsed boxes with a larger box with one input and one output, which is what we are attempting to do through wirings, but rather simply generates one output. Although the possible couplers form a polytope that has these specific wirings as its extremal points, this is not the type of operation we are looking for.

    Taking inspiration from this work, however, we might want to see if the

    % TODO may be possible to form polytope of wirings, but may not be helpful -
    % extremal points may not maximise keyrates

    \subsection{Number of Distinct Wirings}

    Simple combinatorics gives us \(i_A^{j-1} o_A^{j-1}\) possible inputs for \(C_j^A\). However, since \(x_j\) is completely fixed by \({(x_k)}_{k=1}^{j-1}\) and \({(a_k)}_{k=1}^{j-1}\), there are only \(i_A o_A^{j-1}\) valid inputs, with the rest corresponding to don't-cares. Therefore, the number of possible \(C_j^A\) is \(\exp_{i_A}(i_A o_A^{j-1})\). Similarly, the number of possible \(C^A\) is \(\exp_{o_A}(i_A o_A^{c})\). The total number of wirings is then
    \begin{equation}
      \exp_{o_A}(i_A o_A^c) \prod_{j=2}^c \exp_{i_A}(i_A o_A^{j-1}),
    \end{equation}
    where we count from \(j = 2\) because for \(j = 1\), there is only one possibility. The same applies to Bob with the appropriate changes of labels \(A \mapsto B\), \(x \mapsto y\), \(a \mapsto b\). 

    We may wish to fix some input settings to use a given wiring. For example, it is clear that the AND gating can only increase the value of the correlator. Therefore, we can fix the key generating settings \(A_1\) and \(B_3\) to be AND-wired, so that all functions with \(x_1 = 1\) or \(y_1 = 3\) are fixed to the AND wiring. If we fix the wirings for \(f\) input settings, then we are free to choose the outputs for only \(i_A - f\) possible values of \(x_1\), so the number of possible wirings becomes
    \begin{equation}
      \exp_{o_A}((i_A-f) o_A^c) \prod_{j=2}^c \exp_{i_A}((i_A-f) o_A^{j-1})
    \end{equation}
    for Alice, with the analogous relabelling for Bob.

    \subsection{Evaluation}

    Unfortunately, with just two boxes, there are 4096 wirings for Alice, and \(\approx \num{2.48e10}\) for Bob. Fixing the AND gating as discussed above gives us 1024 wirings for Alice and \(\approx \num{3.10e9}\) for Bob. Since the choice of wirings for Alice and Bob are independent, we must multiply the figures for Alice and Bob together, which would make this analysis very inefficient.

    This enumeration of the possible wirings is naive, and does not attempt to use symmetry arguments to remove degeneracy. This is one possible direction for us to investigate, in order to develop a tool to efficiently find the optimal wiring for a given behaviour. However, obtaining a deeper understanding of the problem through these methods seems unlikely. Given a family of behaviours and a figure of merit (either an upper bound or lower bound), it is possible to exhaustively search for the wiring for each particular behaviour that produces the largest increase in the figure of merit. However, since there is no convenient parametrisation or classification of the wirings, it would be difficult to generalise this data or draw any conclusions from it. Attempting to develop such a classification scheme for wirings in order to enable this analysis is another possible direction for this project, which would subsume the symmetry analysis discussed above.

  \section{Upper Bounds}

  There are a number of upper bounds for key rates in the literature, computed using a large variety of techniques. These bounds can be for the keyrate achievable from a specific state, or from a specific behaivour. An important property of an upper bound is whether it is \emph{faithful}: faithful upper bounds are those that have non-zero keyrates for all entangled states or all nonlocal behaviours. For our purposes, a non-faithful upper bound is much more helpful---if local wirings between multiple copies of the same device are able to \emph{revive} the keyrate, that would be very interesting from both theoretical and practical standpoints. Theoretically, it would develop our currently limited understanding of the nature of the \emph{secrecy capacity} of no-signalling behaviours, and practically, it would be an easily-implemented technique that can squeeze secrecy out of a poorly-functioning system.

  A notable non-faithful upper bound is given in~\cite{NotSufficient}, where Eve, who controls the source that provides quantum states for the devices to measure, can sometimes choose to distribute \emph{local correlations}, which she has full information on, while distributing nonlocal correlations at all other times. This \emph{convex combination} attack, so called because the resultant behaviour is a convex combination of the local and nonlocal behaviours, can simulate the correlations that are generated by inefficient projective measurements on Werner states. These behaviours are nonlocal, that is, they have \(S > 2\), but the fact that they were generated in this manner can be used to prove that standard protocols, where both Alice and Bob announce their measurement settings, cannot generate secret keys from them.

  TODO:\ More information on other upper bounds to come.

    \section{Nonlocality Monotones}

    The maximal correlation between two rvs \(A,B\) is denoted as \(\rho(A,B)\) and defined as
    \begin{equation}
      \rho(A,B) = \max_{f,g} \frac{\E[(f(A)-\E[f(A)])(g(B)-\E[g(B)])]}{\sqrt{\Var[f(A)]\Var[g(B)]}}
    \end{equation}
    or equivalently
    \begin{Array}{rcl}
      \rho(A,B) = & \max_{f,g}  & \E[f(A)g(B)] \\
                  & \text{s.t.} & \E[f(A)] = \E[g(B)] = 0 \\
                  &             & \E[f(A)^2] = \E[g(B)^2] = 1.
    \end{Array}

    For the maximal correlation \(\rho(A,B|X=x,Y=y)\), where we simply use the conditional distributions in place of the unconditioned distributions, we define the matrices
    \begin{align}
      \matrp{P}{_{AB|xy}}_{ab} &= \Pr(A = a, B = b|X = x, Y = y) \\
      \matrp{P}{_{A|x}}_{ab} &= \delta_{ab} \Pr(A = a|X = x) \\
      \matrp{P}{_{B|y}}_{ab} &= \delta_{ab} \Pr(B = b|Y = y) \\
      \matrp{\tilde{P}}{_{AB|xy}} &= \matrp{P}{_{A|x}}^{-1/2} \matrp{P}{_{AB|xy}} \matrp{P}{_{B|y}}^{-1/2} \\
      \therefore \matrp{\tilde{P}}{_{AB|xy}}_{ab} &= \frac{p(a,b|x,y)}{\sqrt{p(a|x)p(b|y)}},
    \end{align}
    where \(\matrp{P}{_{A|x}}_{ab}\), \(\matrp{P}{_{B|y}}_{ab}\), \(\matrp{P}{_{AB|xy}}_{ab}\) and \(\matrp{\tilde{P}}{_{AB|xy}}\) have dimensions \(o_A \times o_A\), \(o_B \times o_B\), \(o_A \times o_B\), \(o_A \times o_B\) respectively. We use the Moore-Penrose inverse for this inversion, which, since \(\matrp{P}{_{A|x}}_{ab}\) and \(\matrp{P}{_{B|y}}_{ab}\) are diagonal, involves inverting their non-zero diagonal entries and leaving the zero entries in place.

    Let the singular values of \(\matrp{\tilde{P}}{_{AB|xy}}\) be \(\lambda_i\) for \(i \in [1, \min\{o_A, o_B\}] \cap \Z\) such that \(\lambda_{i} \geq \lambda_{i+1}\),
    \begin{equation}
      \rho(A,B|X=x,Y=y) = \lambda_2\left( \matrp{\tilde{P}}{_{AB|xy}} \right).
    \end{equation}

    Working with the normalised form of the maximum correlation function, and so considering only normalised functions, we have
    \begin{align}
      \E[f(A)g(B)|xy] &= \sum_{a,b} p(a,b|x,y) f(a)g(b) \\
                      &= \sum_{a,b} \sqrt{p(a|x)} f(a) \frac{p(a,b|x,y)}{\sqrt{p(a|x)p(b|y)}} \sqrt{p(b|y)} g(b) \\
                      &= \rvec{f} \matrp{\tilde{P}}{_{AB|xy}} \cvec{g},
    \end{align}
    where we have defined
    \begin{equation}
      \cvec{f} = {[\sqrt{p(a|x)} f(a)]}^T_a \qquad \cvec{g} = {[\sqrt{p(b|y)} g(b)]}^T_b.
    \end{equation}
    The technicalities arising from cases where \(p(a|x)\) or \(p(b|y)\) are zero, and therefore \(p(a,b|x,y) = 0\), are handled by the Moore-Penrose inverse, which maps those entries of \(\matrp{\tilde{P}}{_{AB|xy}}\) to zero.

    We also represent \(\matrp{\tilde{P}}{_{AB|xy}}\) in its compact singular value decomposition as
    \begin{equation}
      \matrp{\tilde{P}}{_{AB|xy}} = \sum_i \lambda_i \cvec{u}_i \rvec{v}_i,
    \end{equation}
    where \(\{\cvec{u}_i\}\) and \(\{\cvec{v}_i\}\) are sets of orthonormal vectors in \(\R^{o_A}\) and \(\R^{o_B}\) respectively.

    It is known that~\cite[Thm 1]{ComputingMaxCorr} \(\lambda_i \in [0, 1]\), and
    \begin{equation}
      \lambda_1 = 1 \qquad \cvec{u}_1 = {[\sqrt{p(a|x)}]}_a^T \qquad \cvec{v}_1 = {[\sqrt{p(b|y)}]}_b^T.
    \end{equation}
    This gives us that
    \begin{align}
      \rvec{f} \cvec{u}_1 &= \sum_a p(a|x) f(a) = \E[f(A)|x] = 0 \\
      \norm{\cvec{f}}_2 &= \sum_a p(a|x) {f(a)}^2 = \E[{f(A)}^2|x] = 1 \\
      \rvec{v}_1 \cvec{g} &= \sum_b p(b|y) g(b) = \E[g(B)|y] = 0 \\
      \norm{\cvec{g}}_2 &= \sum_b p(b|y) {g(b)}^2 = \E[{g(B)}^2|y] = 1.
    \end{align}

    The singular value decomposition can be characterised variationally by
    \begin{Array}{rcl}
      \lambda_1(\matr{M}) = & \max_{\cvec{f},\cvec{g}} & \rvec{f} \matr{M} \cvec{g} \\
                            & \text{s.t.} & \norm{\cvec{f}}_2 = \norm{\cvec{g}}_2 = 1, \\
    \end{Array}
    for an arbitrary matrix \(\matr{M}\) by using Lagrange multipliers to constrain \(\cvec{f}\) and \(\cvec{g}\). This maximum is achieved by \(\cvec{f} = \cvec{u}_1\), \(\cvec{g} = \cvec{v}_1\). With the additional constraint of \(\rvec{f} \cvec{u}_1 = \rvec{v}_1 \cvec{g} = 0\), the maximum is \(\lambda_2(\matr{M})\), achieved by \(\cvec{f} = \cvec{u}_2\), \(\cvec{g} = \cvec{v}_2\). We can apply this property directly to find the maximal correlation, and the functions which achieve it, from the singular value and corresponding singular vectors for \(i = 2\).

    Observe that, for \(K_A\) and \(K_B\), two perfectly correlated and uniformly distributed secret keys, we have \(\rho(K_A, K_B) = 1\), with the maximum achieved by mapping half of the keys to \(1\) and half to \(-1\) for both \(f\) and \(g\). However, if the two keys are independent, then \(\rho(K_A,K_B) = \E[f(K_A)g(K_B)] = \E[f(K_A)]\E[g(K_B)] = 0\). Likewise, if the two keys are deterministic (not secret), then \(f(K_A) = g(K_B) = 0\) and so \(\rho(K_A, K_B) = 0\). However, this poses an issue for longer keys. Even if there are only two possible values for the key, as long as they are uniformly distributed, \(\rho(K_A, K_B) = 1\), even though Alice and Bob effectively share only one bit of secrecy! Therefore, we need to find a bound that looks something like
    \begin{equation}
      \max_{E|AB} \frac{H(A|E) - H(A|B)}{H(A)} \leq f(\rho(A,B)).
    \end{equation}

    Some other related measures are the hypercontractivity (HC) ribbon:
    \begin{equation}
      \HC(A,B) = \{(\lambda_A, \lambda_B) \in {[0,1]}^2 \st \forall U, \lambda_A I(U;A) + \lambda_B I(U;B) \leq I(U;AB)\},
    \end{equation}
    or equivalently,
    \begin{equation}
      \HC(A,B) = \{(\lambda_A, \lambda_B) \in {[0,1]}^2 \st \forall f,g; \E[f(A)g(B)] \leq {\E[\abs{f(A)}^{1/\lambda_A}]}^{\lambda_A} {\E[\abs{g(B)}^{1/\lambda_B}]}^{\lambda_B} \},
    \end{equation}
    or, with \(\Upsilon_{AB}(\lambda_A, \lambda_B) = \lambda_A H(A) + \lambda_B H(B) - H(AB)\) and \(\tilde{\Upsilon}_{AB}\) its lower convex envelope (pointwise largest convex function that fulfills \(\tilde{\Upsilon}_{AB}(\lambda_A, \lambda_B) \leq \Upsilon_{AB}(\lambda_A, \lambda_B)\) for all \(\lambda_A, \lambda_B\)):
    \begin{equation}
      \HC(A,B) = \{(\lambda_A, \lambda_B) \in {[0,1]}^2 \st \Upsilon_{AB}(\lambda_A, \lambda_B) = \tilde{\Upsilon}_{AB}(\lambda_A, \lambda_B) \};
    \end{equation}
    and the maximal correlation (MC) ribbon:
    \begin{equation}
      \MC(A,B) = \{(\lambda_A, \lambda_B) \in {[0,1]}^2 \st \forall f; \Var[f(A,B)] \geq \lambda_A \Var_A[\E_{B|A}[f(A,B)]] + \lambda_B \Var_B[\E_{A|B}[f(A,B)]] \},
    \end{equation}
    which can be normalised by restricting to \(\E[f(A,B)] = 0\), giving
    \begin{equation}
      \MC(A,B) = \{(\lambda_A, \lambda_B) \in {[0,1]}^2 \st \forall f; \E[{f(A,B)}^2] \geq \lambda_A \E_A[{(\E_{B|A}[f(A,B)])}^2] + \lambda_B \E_B[{(\E_{A|B}[f(A,B)])}^2] \}.
    \end{equation}
    These ribbons can be defined as the union of the ribbons for the conditional distributions for the boxes, and are notable because they expand under wirings and occupy the whole of \({[0,1]}^2\) for independent variables.

    The relations between them are
    \begin{gather}
      {\rho(A,B)}^2 = \inf_{\substack{(\lambda_A, \lambda_B) \in \MC(A,B) \\ \lambda_B \neq 0}} \frac{1 - \lambda_A}{\lambda_B} \\
      \HC(A,B) \subseteq \MC(A,B) \\
      s^*(A,B) \coloneqq \inf_{\substack{(\lambda_A, \lambda_B) \in \HC(A,B) \\ \lambda_B \neq 0}} \frac{1 - \lambda_A}{\lambda_B} \geq {\rho(A,B)}^2
    \end{gather}

    \section{Correlation Space for (2, 2, 3, 2)}

    We have 24 positivity facets of the local polytope, and 24 liftings of CHSH\@.

    \section{State of the Art Lower Bounds}

    \subsection{Asymmetric CHSH}

    Better key rates have been obtained from asymmetric versions of the CHSH inequality:
    \begin{equation}
      S_{\alpha} \coloneqq \alpha\angleb{A_0 B_0} + \alpha\angleb{A_1 B_0} + \angleb{A_0 B_1} - \angleb{A_1 B_1}.
    \end{equation}
    This technique can then be combined with noisy preprocessing, where Alice replaces each bit of her key with a locally random bit with probability \(q\). The lower bound for \(H(A_0|E)\), with \(s = S_{\alpha}\) from the test statistics, is
    \[ H(A_0|E) \geq g_{q,\alpha}(s) = \begin{cases}
      g(s) & \text{ for } \abs{\alpha} \geq 1 \text{ or } s \geq s^* \\
      h(q) + g'(s^*)(\abs{s}-2) & \text{ otherwise},
    \end{cases}
    \]
    where
    \begin{equation}
      g_{q,\alpha}(s) = 1 + \phi\left(R_1\right) - \phi\left(R_2\right),
    \end{equation}
    with
    \begin{equation} 
      R_1 = \sqrt{{(1-2q)}^2 + 4q(1-q)(s^2/4-\alpha^2)} \qquad R_2 = \sqrt{s^2/4-\alpha^2}
    \end{equation}
    and where \(s^*\) is the solution to
    \begin{equation}\label{eqn:sstar}
      h(q) + g'(s^*) (s^*-2) = g(s^*).
    \end{equation}

    For a function \(R(s)\) of \(s\), it can easily be verified that
    \begin{equation}
      \diff{\phi(R)}{s} = \frac{1}{2} \diff{R}{s} \log\frac{1-R}{1+R},
    \end{equation}
    and since
    \begin{equation} 
      R_1'(s) = \frac{qs(1-q)}{R_1} \qquad R_2'(s) = \frac{s}{4R_2},
    \end{equation}
    we have
    \begin{equation}
      g_{q,\alpha}'(s) = \frac{qs(1-q)}{2R_1} \log\frac{1-R_1}{1+R_1} - \frac{s}{4R_2} \log\frac{1-R_2}{1+R_2}.
    \end{equation}

    \subsection{The BFF Method}

    The essential idea is very straightforward---in order to efficiently minimise the von Neumann entropy \(H(A|E, X = x^*)\), we upper-bound the relative entropy between the variable system and the perfectly mixed (secret) key. % TODO

    However, the methods involved in casting the relative entropy into an easily optimised form are highly involved, using the operator algebra approach to quantum mechanics. We will briefly review some of the ideas used in this paper that are generally not covered in undergraduate treatments of quantum mechanics and quantum information.
    % TODO this is just to ease the generalisation to continuous

    The set of \emph{bounded operators} \(\mathcal{B}(\Hs)\) on the Hilbert space \(\Hs\) is the set \(\mathcal{L}(\Hs)\) of all linear operators on \(\Hs\) such that the \emph{operator norm} of \(X \in \mathcal{L}(\Hs)\)
    \[ \norm{X} \coloneqq \sup_{\psi \in \Hs \setminus \{0\}} \frac{\norm{X\psi}}{\norm{\psi}} \]
    is finite. For an operator \(A\), its \emph{spectrum} \(\sigma(A)\) is the subset of \(\C\) such that, for all \(\lambda \in \sigma(A)\), \(A - \lambda I\) does not have a \emph{bounded inverse}: there does not exist an operator \(S\) such that \(S\left( A - \lambda I \right) = \left( A - \lambda I \right)S =  I\) and \(S \in \mathcal{B}(\Hs)\).

    Our objective is to establish a \emph{functional calculus} that will allow us to evaluate a function  \(f\) with scalar output on operators. In the finite-dimensional case this is straightforward for normal operators (obeying \(AA^{\dagger} = A^{\dagger}A\)): for an operator \(A\) with eigenvalues \(\{\lambda_i\}\) and corresponding eigenprojectors \(\{\Pi_i\}\),
    \[ A = \sum_i \lambda_i \Pi_i \Rightarrow f(A) = \sum_i f(\lambda_i) \Pi_i, \]
    by the \emph{spectral theorem}.

    However, the approach of the paper generalises the spectral theorem to cases where the spectrum \(\sigma(A)\) is no longer a discrete set of eigenvalues, as it is in the finite-dimensional case, but a \emph{continuous spectrum}. This scenario arises in infinite-dimensional Hilbert spaces, such as those involving position and momentum operators. These particular operators are even more complex, since they are \emph{unbounded}. We will therefore sketch the standard statement of the spectral theorem, which applies to bounded normal operators and unbounded self-adjoint (\(A = A^{\dagger}\)) operators, although we leave aside technicalities regarding the domain of the operators and the functions involved in this generalisation.

    This requires some additional definitions. \emph{Spectral measures}, or \emph{projector-valued measures} (PVMs), map a subset of the spectrum to a projector. More formally, they are functions between the \emph{\(\sigma\)-algebra} \(\Omega(\sigma(A))\) of \(\sigma(A)\) to \(\mathcal{B}(\Hs)\). A \(\sigma\)-algebra contains subsets of its underlying set, and is closed under set complements and unions of countable sequences, so in this case it represents subsets of the spectrum that it would be sensible to attach a projector to.

    In the finite-dimensional case, the projector associated to each eigenvalue \(\lambda\) in the spectrum is the projector onto the associated eigenspace, and the direct sum of the projectors is the projector onto \(\Hs\), that is, \(I\). With a continuous spectrum, we want to divide \(\Hs\) into orthogonal spaces in the same way, providing a systematic way to attach each subspace to each element \(\omega \in \Omega(\sigma(A))\), that is, each reasonable subset of \(\sigma(A)\). Under a given spectral measure \(E : \Omega(\sigma(A)) \to \mathcal{B}(\Hs)\), the subspace \(V_{\omega} \subseteq \Hs\) associated to \(\omega\) is called a \emph{spectral subspace}, and \(E(\omega)\) is the projector onto \(V_{\omega}\). These \(V_{\omega}\) are ``generalised eigenspaces'' in the sense that they are \emph{invariant} under \(A\), that is, \(\psi \in V_{\omega} \Rightarrow A\psi \in V_{\omega}\), and that, for \(\omega \subseteq [\lambda - \epsilon, \lambda + \epsilon]\), we have \(\norm{(A - \lambda I)\psi} \leq \epsilon\norm{\psi}\), from which recover the familiar behaviour when the spectrum is discrete.

    A function \(f : \sigma(A) \to \C\) can then be applied to an element of \(\mathcal{B}(\Hs)\), by integrating it against this measure
    \[ f(A) = \int_{\lambda \in \sigma(A)} f(\lambda) \dif{E(\lambda)}, \]
    where we have that
    \[ \int_{\lambda \in \sigma(A)} \delta\{\lambda \in \omega\} \dif{E(\lambda)} = E(\omega), \]
    with the \emph{indicator function} \(\delta\{P\} = 1\) when \(P\) is true, and 0 otherwise. This property can be used to define the integral for any other function. For example, for a given function \(f : \R \to \C\), we can define a sequence of functions
    \[ f_n(\lambda) = \sum_{j = -\infty}^{\infty} f(j/n) \delta\{\lambda \in [j/n, (j+1)/n)\}, \]
    and if this sequence \emph{converges uniformly} to \(f(\lambda)\), that is,
    \[ \forall \lambda \in \C; \lim_{n \to \infty} \norm{f_n(\lambda) - f(\lambda)} = 0, \]
    then
  \[ f(A) = \lim_{n\to\infty} \int_{\lambda \in \sigma(A)} f_n(\lambda) \dif{E(\lambda)} = \lim_{n\to\infty} \sum_{j = -\infty}^{\infty} f(j/n) E([j/n, (j+1)/n)) \]
  so that, roughly speaking, the effect of \(f(A)\) on \(E([\lambda, \lambda+\dif{\lambda}))\psi\) is multiplication by \(f(\lambda)\). The \emph{spectral theorem} then asserts that there is a \emph{unique} measure \(E_A\) on the Borel \(\sigma\)-algebra, that is, the smallest \(\sigma\)-algebra containing all open sets in \(\sigma(A)\), such that
  \[ A = \int_{\sigma(A)} \lambda \dif{E_A(\lambda)}, \]
  which is how \(A\) can be decomposed into orthogonal projectors.

  An operator-valued measure \(E\) on \(\sigma(A)\) can be converted into a regular, scalar-valued measure \(\nu\) by specifying a vector \(\phi\), so that
  \[ \int_{\sigma(A)} f(\lambda) \dif{\nu(\lambda)} = \angleb{\phi, \left(\int_{\sigma(A)} f(\lambda) \dif{E(\lambda)}\right) \phi}. \]

  A \emph{joint spectral measure} of multiple self-adjoint operators, with \emph{commuting spectral measures} (which then implies that the operators commute) is then simply the product of their respective spectral measures, with a straightforward generalisation from the single-operator case.

  % TODO replace \sigma(A) with \mathcal{X} and explain the use of joint spectral
  % measures in the paper

 \end{document}

  Compute relative entropy of entanglement and compare to quantum maximal correlation
